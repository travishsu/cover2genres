{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AtrousConvolution2D, Flatten, Dense, MaxPooling2D, Dropout, ZeroPadding2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load label and rename data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Release Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 X 5_1964</td>\n",
       "      <td>rock pop bluesrock</td>\n",
       "      <td>1964-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Rolling Stones_1964</td>\n",
       "      <td>rock blues pop poprock rhythmblues rockroll</td>\n",
       "      <td>1964-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's All Over Now_1964</td>\n",
       "      <td>rock rhythmblues classicrock</td>\n",
       "      <td>1964-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December's Children (And Everybody's)_1966</td>\n",
       "      <td>rock bluesrock garagerock poprock</td>\n",
       "      <td>1966-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No. 2_1965</td>\n",
       "      <td>rock bluesrock rockroll</td>\n",
       "      <td>1965-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Filename  \\\n",
       "0                                 12 X 5_1964   \n",
       "1                     The Rolling Stones_1964   \n",
       "2                      It's All Over Now_1964   \n",
       "3  December's Children (And Everybody's)_1966   \n",
       "4                                  No. 2_1965   \n",
       "\n",
       "                                        Genres         Release Year  \n",
       "0                           rock pop bluesrock  1964-01-01 00:00:00  \n",
       "1  rock blues pop poprock rhythmblues rockroll  1964-01-01 00:00:00  \n",
       "2                 rock rhythmblues classicrock  1964-01-01 00:00:00  \n",
       "3            rock bluesrock garagerock poprock  1966-01-01 00:00:00  \n",
       "4                      rock bluesrock rockroll  1965-01-01 00:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/set2/\"\n",
    "data_type = {\"Filename\": str, \"Genres\": str, \"Release Year\": int}\n",
    "albums = pd.read_csv(data_dir + \"albumlabel.csv\", dtype=data_type, parse_dates=[\"Release Year\"])\n",
    "# albums['Artist'] = [name.split('_')[1] for name in albums['Filename']]\n",
    "# albums['NewFileName'] = albums['Artist'] +'_'+ albums['Release Year'].map(lambda x: str(x)[:10])\n",
    "albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/set2/resize\\\\E\\xa1ES\\xa1EP_1987.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cd6c1eafd701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'resize'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"resize/*.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\albert.cheng\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\scipy\\misc\\pilutil.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \"\"\"\n\u001b[1;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\albert.cheng\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\PIL\\Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/set2/resize\\\\E\\xa1ES\\xa1EP_1987.jpg'"
     ]
    }
   ],
   "source": [
    "# Resize pictures\n",
    "setpath = 'data/set2/'\n",
    "subprocess.call(['rm', '-rf', setpath+'resize'])\n",
    "subprocess.call(['cp', '-r', setpath+'img', setpath+'resize'])\n",
    "for pic in glob.glob(setpath+\"resize/*.jpg\"):\n",
    "    img = imread(pic)\n",
    "    img = imresize(img, (32, 32))\n",
    "    imsave(pic, img)\n",
    "\n",
    "# # File rename\n",
    "# for i in xrange(albums.shape[0]):\n",
    "#     subprocess.call(['mv', data_dir+'resize/'+albums['Filename'].loc[i]+'.jpg',\\\n",
    "#                      data_dir+'resize/'+albums['NewFileName'].loc[i]+'.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Label to index number New genres (12 groups)\n",
    "token = Tokenizer()\n",
    "genres = ['rock', 'metal', 'punk', 'pop', 'blue', 'funk', 'jazz', 'electro', 'hiphop', 'rap', 'country', 'other']\n",
    "token.fit_on_texts(genres)\n",
    "for k in token.word_index:\n",
    "    token.word_index[k] -= 1\n",
    "\n",
    "idx_word = dict()\n",
    "for key in token.word_index.keys():\n",
    "    idx_word[token.word_index[key]] = key\n",
    "\n",
    "label_lst = albums.Genres.get_values()\n",
    "data_y = np.zeros((len(label_lst), max(token.word_index.values())+1))\n",
    "for i, album_labels in enumerate(label_lst):\n",
    "    splt_labels = album_labels.split()\n",
    "    for label in splt_labels:\n",
    "        nl = [l for l in token.word_index if l in label]\n",
    "        if len(nl) > 0:\n",
    "            for j in nl:\n",
    "                data_y[i, token.word_index[j]] = 1\n",
    "        else:\n",
    "            data_y[i, token.word_index['other']] = 1\n",
    "print data_y[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue': 0, 'metal': 1, 'rock': 9, 'jazz': 2, 'punk': 3, 'pop': 4, 'hiphop': 6, 'other': 7, 'rap': 8, 'country': 5, 'electro': 10, 'funk': 11}\n",
      "[  325.   408.    68.    75.   928.    71.   713.  1096.   186.  1608.\n",
      "   542.   207.]\n"
     ]
    }
   ],
   "source": [
    "print token.word_index\n",
    "print np.sum(data_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/set2/resize/12 X 5_1964.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dfd1bd4d2ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Read image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_origin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'resize/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malbums\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_origin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_origin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_origin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\albert.cheng\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\PIL\\Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/set2/resize/12 X 5_1964.jpg'"
     ]
    }
   ],
   "source": [
    "# Read image\n",
    "X_origin = np.array([np.array(Image.open(data_dir+'resize/'+filename+'.jpg')) for filename in albums['Filename'].get_values()])\n",
    "X = np.zeros((X_origin.shape[0], 32, 32, 3))\n",
    "for i in xrange(X_origin.shape[0]):\n",
    "    X[i] = X_origin[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = 'adadelta'\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "def center_normalize(x):\n",
    "    return (x - K.mean(x)) / K.std(x)\n",
    "\n",
    "def single2multi(x):\n",
    "    return x/np.max(x)\n",
    "\n",
    "# split data\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build NN Model (model to optimize)\n",
    "model = Sequential()\n",
    "model.add(Activation(activation=center_normalize,input_shape=train_x.shape[1:]))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1),input_shape=train_x.shape[1:], dim_ordering='tf'))\n",
    "model.add(Conv2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(train_y.shape[1], activation='sigmoid'))\n",
    "# model.add(Dense(train_y.shape[1], activation=single2multi))\n",
    "\n",
    "model.compile(loss=objective,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
    "model.fit(train_x, train_y,\n",
    "          validation_data = (test_x, test_y),\n",
    "          batch_size=5,\n",
    "          nb_epoch=10,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greater50percent(y):\n",
    "    p = []\n",
    "    for s in y:\n",
    "        tmp = []\n",
    "        for i in xrange(len(s)):\n",
    "            if s[i] > 0.5:\n",
    "                tmp.append(i)\n",
    "        p.append(tmp)\n",
    "    return p\n",
    "\n",
    "pred = model.predict(test_x)\n",
    "p  = greater50percent(pred)\n",
    "p_ = greater50percent(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(data_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(p)):\n",
    "    print(i, p[i], p_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_req(filename, model):\n",
    "    reqdata = np.array([np.array(Image.open(filename))])\n",
    "    return model.predict(reqdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_req(data_dir+'resize/'+'Megadeth_1986-01-01.jpg', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
